# Mashine-Learning
In this repository,  I will sort out some knowledge points about machine learning.
决策学习目的：一棵泛化能力强，即处理未见示例能力强的决策树，基本流程为"分而治之"

信息熵(information entropy)是度量样本集合纯度最常用的一种指标
ID3决策树学习算法：信息增益越大，使用属性a来进行划分所获得的"纯度提升"越大
信息增益准则对可取值数目较多的属性有所偏好，C4.5决策树算法不直接使用信息增益，使用"增益率"来选择最优划分属性
增益率准则对可取值数目较少的属性有所偏好，因此C4.5决策树算法不是直接选择增益率最大的候选划分属性，而是使用一个启发性：
         先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择增益率最高的属性
CART决策树(classification and regression tree)使用"基尼指数"来选择划分属性
Gini(D)反映了从数据集D中随机抽取两个样本，其类别标记不一致的概率

剪枝处理：a.预剪枝(perpuning) --> 对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前节点标记为叶结点
                               基于"贪心"本质禁止某些分支展开，给预剪枝决策树带来了欠拟合的风险
         b.后剪枝(postpuning) --> 先从训练集生成一棵完整的决策树，然后从底向上对非叶子节点考察，看替代为叶子节点效果怎样
         
贪心算法是指：在每一步的求解步骤中，她"要求"贪婪地选择最佳操作，并通过一系列的最优选择，能够产生一个问题的最优解
                                 
