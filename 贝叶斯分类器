# Mashine-Learning
In this repository,  I will sort out some knowledge points about machine learning.
贝叶斯决策论是概率框架下实施决策的基本方法
贝叶斯判定准则：为最小化总体风险，只需在每个样本上选择那个使条件风险R(c|x)最小的类别标记
               或选择能使后验概率P(c|x)最大的类别标记               

机器学习目标： 基于有限的训练样本集尽可能准确地估计出后验概率 p(c|x)
概率模型训练的过程就是参数估计过程
A.判别式模型：寻找不同类别之间的最优分类面，反映异类数据之间的差异 --> SVM、决策树、条件随机场
B.生成式模型：以统计的角度表示数据的分布情况，能够反映同类数据本身的相似度

MLE(Maximum Likelihood Estimation, 极大似然估计) 特点：估计结果的准确性严重依赖于所假设的概率分布形式是否符合潜在的真实数据分布
朴素贝叶斯分类器 --> "属性条件独立性假设"
为了避免其他属性携带的信息被训练集中未出现的属性值"抹去"，在估计概率值时通常要进行"平滑"，常用"拉普拉斯修正"
现实任务中朴素贝叶斯分类器的使用：查表、懒惰学习(典型代表:knn)

半朴素贝叶斯分类器：适当考虑一部分属性间的相互依赖信息，从而既不需要完全联合概率计算，又不至于忽略较强的属性依赖关系
"独依赖估计": 假设每个属性在类别之外最多仅依赖一个其他属性
A. "超父"(super parent) -->假设所有属性都依赖于同一个属性(SPODE)
B. TAN(最大带权生成树) --> 实际保留了强相关属性之间的依赖性
C. AODE基于集成学习机制，尝试将每个属性作为超父来构建SPODE，然后将具有足够训练数据支撑的SOPDE集成起来作为最终结果
多属性依赖假设：若训练数据非常充分，泛化性能有可能提升；若样本数量有限，则会陷入估计高阶联合概率的泥沼

贝叶斯网(Bayesian network),借助有向无环图(Directed Acyclic Graph, DAG)来刻画属性之间的依赖关系，
并使用条件概率表(Conditional Probability Table, CPT)来描述属性的联合概率分布
道德图(moral graph),令父节点相连的过程称为"道德化"(moralization)

怎样得到贝叶斯网？ --> 评分搜索
评分函数通常基于信息论准则，此类准则将学习问题看作一个数据压缩任务，学习目标是找到一个能以最短编码长度描述训练数据的模型
MDL(Minimal Description, 最小描述长度准则)，选择综合编码长度(包括描述网络和编码数据)最短的贝叶斯网
a. AIC评分函数  b.BIC评分函数  c.f(&)==0时，退化为极大似然估计
若网络结构G固定，则只需对网络结构进行搜索，候选结构的最优参数可直接在训练集上得到
最优贝叶斯结构是NP-hard问题 --> a.贪心法  b.给网络结构施加约束来削减搜索空间

已知变量观测值来推测待查询变量的过程称为"推断"，已知变量观测值称为"证据"
近似推断 --> 吉布斯采样，一种随机采样方法 缺点是收敛速度较慢，若贝叶斯网存在极端概率'0'或'1'，则会出错
EM算法(Expectation Maximization, 期望最大化算法)，一种非梯度优化算法，常被用来学习高斯混合模型(GMM)的参数
A. E步: 利用当前估计的参数值来计算对数似然的期望值
B. M步: 最大化，寻找能使E步产生的似然期望值最大化的参数值
