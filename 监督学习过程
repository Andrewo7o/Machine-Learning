# Mashine-Learning
In this repository,  I will sort out some knowledge points about machine learning.
批量梯度下降(BGD，Batch Gradient Descent)
随机梯度下降(SGD,Stochastic Gradient Descent)
小批量梯度下降(MBGD，Mini-batch Gradient Descent)

损失函数计算的是一个样本的误差
代价函数计算的是整个训练集上所有样本误差的平均
目标函数 = 代价函数 + 正则化项
损失函数取得最小值的方法： a.最小二乘法  b.随机梯度下降法
解决模型过拟合： a.尽量减少选取变量的数量  b.正则化

回归从数学上来讲就是给定一个点集，能够用一条曲线去拟合之
如果曲线是一条直线，那就被称为线性回归  
如果曲线是一条二次曲线，就被称为二次回归

偏差描述的是算法的预测平均值与真实值之间的关系(算法拟合能力如何)
方差描述的是同一个算法在不同数据集上的预测值和所有数据集上的平均预测值之间的关系(算法的稳定性如何)

交叉验证：
A.简单交叉验证：70%训练集，30%测试集 --> 反复
B.S折交叉验证：S份，(S-1)份为训练集，1份为测试集 --> 反复
C.留一交叉验证：用于样本非常少的情况  数据量很少时也可用自助采样法
